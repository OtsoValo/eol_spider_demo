#!/bin/bash
cd /data/eol_spider_demo
echo "开始无限循环爬取"
i=0
while true
do
    ((i=i+1));
    echo "开始第$i次爬取"
    #scrapy crawl ResearchGateSpider -s JOBDIR=crawls/ResearchGateSpider-3
    scrapy crawl ResearchGateSpider -s JOBDIR=/data/seen
    #echo "已抓取文件数"
    #tree -i .scrapy/ | grep directories
    echo "切换ip"
    /usr/bin/changeip
    echo "休息6秒"
    sleep 6
    echo "检查网络状况..."
    while true
    do
      ping=`ping -c 6 www.baidu.com|awk 'NR==7 {print int($4)}'`
      if [ $ping -ne 0 ];then
          echo "连续ping通6次www.baidu.com，网络ok"
          break;
      else
          echo "切换ip2"
          /usr/bin/changeip
          echo "休息6秒2"
          sleep 6
          echo "检查网络状况2..."
          while true
          do
             ping=`ping -c 6 www.baidu.com|awk 'NR==7 {print int($4)}'`
             if [ $ping -ne 0 ];then
                 echo "连续ping通3次www.baidu.com，网络ok2"
                 break;
             fi
          done
      
      fi
    done
done
